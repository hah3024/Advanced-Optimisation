{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igs4z8zGtZp4"
      },
      "source": [
        "# Coursework Applied Advanced Optimisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwY8e6pZtdh2"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "**Author:** Dr Giordano Scarciotti (g.scarciotti@imperial.ac.uk) - Imperial College London\n",
        "\n",
        "**Module:** ELEC70066 - Applied Advanced Optimisation\n",
        "\n",
        "**Version:** 1.1.1 - 29/01/2025\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYuwkc1UtxfN"
      },
      "source": [
        "This coursework covers some of the so-called \"geometric problems\". These problems belong to an additional family of applications which complements Chapter $1$ (Approximation and Fitting) and Chapter $2$ (Statistical Estimation). Geometric problems cover many important applications, the most famous of which is machine learning. In fact, the popular Support Vector Machines are a family of classification methods which are nothing else than convex optimisation problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJqyQ8p739pH"
      },
      "source": [
        "# Important instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3eqOnha4ItJ"
      },
      "source": [
        "You must read this section in its entirety before starting the coursework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8L2zdnO4R2A"
      },
      "source": [
        "This coursework is intended to be an occasion for you to explore an optimisation topic in autonomy. The coursework is based on \"Section $8.6$ Classification\" of the reference book $[1]$ (link available on Blackboard). You are supposed to read that section to be able to complete the coursework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW3BnDbF4BTo"
      },
      "source": [
        "You cannot use the sklearn library, nor any other library in which SVM or other classifiers are already implemented. The objective of the coursework is that you learn how these classifiers are obtained from scratch. This means that you will have to use your knowledge of Convex Optimisation and CVX to solve the questions directly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65qgOckt5_N-"
      },
      "source": [
        "You must copy this notebook to your drive; work on the file and submit the completed .ipynb file to Blackboard. Before submitting, make sure that you run all the code cells and save the notebook. This will ensure that the notebook looks exactly how you intend it to look. Obviously it is expected that your submission will have plenty of text cells in which you explain your work.\n",
        "\n",
        "The coursework consists of 8 questions. Create a new section for each question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsTo7Ecu7IOl"
      },
      "source": [
        "Generally speaking, no help will be provided on the coursework besides clarifications on the wording of the text. You need to figure out by yourself how to solve the coursework. Note that after reading Section $8.6$ of the book, you will have all the required information to be able to solve the coursework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVg9ZMiF7cNJ"
      },
      "source": [
        "The coursework is an individual piece of assessment. You can discuss it with other students, but you cannot develop solutions together and you cannot share code, text or figures. You cannot ask other people (including online forums) to solve any part of the coursework on your behalf. Standard plagiarisms policy will be applied.\n",
        "\n",
        "The use of generative AI tools is not allowed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PcdLqvBwDFb"
      },
      "source": [
        "# The problem and data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oMguGOox-sL"
      },
      "source": [
        "In pattern recognition and classification problems we are given two sets of points in $\\mathbb{R}^n$, $\\{x_1,\\dots,x_N\\}$ and $\\{y_1,\\dots,y_M\\}$, and wish to find a function $f : \\mathbb{R}^n \\to \\mathbb{R}$ (within a given family of functions) that is positive on the first set and negative on\n",
        "the second, i.e.,\n",
        "\n",
        "$$\n",
        "f(x_i) > 0,\\quad i = 1,\\dots,N, \\qquad f(y_i) < 0,\\quad i = 1, \\dots ,M.\n",
        "$$\n",
        "\n",
        "If these inequalities hold, we say that $f$ separates, classifies, or discriminates the two sets of points. This is an instance of supervised learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4AJLb2JyyxK"
      },
      "source": [
        "In the next subsections you will find $4$ datasets which will be used in the questions below. For datasets $1$, $2$ and $3$ you are given a \"train set\" and a \"test set\". You are supposed to develop your optimisation algorithm only on the train set. Do not use the test set for training/optimisation. The purpose of the test set is for you to test a posteriori how the classifier that you have obtained performs. For data set $4$, use the entire set in the optimisation (i.e. there is no test phase)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkGSTu0CyV0U"
      },
      "source": [
        "### Dataset 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xIbEqjnzwMxU"
      },
      "outputs": [],
      "source": [
        "# Dataset 1. DO NOT CHANGE THE NUMBERS\n",
        "import numpy as np\n",
        "X_train_1 = np.array([[ 1.75038375,  1.36985822,  0.73076475,  0.73666559,  0.34224149,\n",
        "         1.09826685,  0.86211442,  1.24674778,  0.12887349,  0.35909321,\n",
        "         0.35246291,  0.63681688,  0.54697422,  0.76350366,  1.5921626 ,\n",
        "         0.51972449,  1.09117696,  1.42626192,  1.06227916,  0.21480643,\n",
        "         1.42300815,  0.84256355,  1.7533684 ,  0.69974175,  0.76946708,\n",
        "        -0.18379672,  1.0485532 ,  0.96472069,  1.31625354,  0.36578051,\n",
        "         0.77772201,  1.64143191],\n",
        "       [-0.16275141, -0.82300504, -1.30848519, -0.99270645, -1.81370696,\n",
        "         2.8696898 , -1.06625993, -0.73442029,  0.50866809, -0.99408544,\n",
        "         0.40021373, -0.10562573,  0.30068813, -0.18723889,  1.5299066 ,\n",
        "         0.23149303,  0.21033337, -0.37766466,  1.7832445 ,  0.77048214,\n",
        "         2.38601163, -0.12591569,  0.58083659, -0.21862494,  1.21901444,\n",
        "        -0.70226941,  1.82745304,  1.02706123, -1.21456594, -0.04151123,\n",
        "         0.57038679,  0.37708978]]).T\n",
        "\n",
        "Y_train_1 = np.array([[-1.61978158, -1.42158013, -1.10032926, -0.84133058, -1.61746142,\n",
        "        -1.37001245, -0.81530917, -2.19997218, -1.17612194,  0.28991103,\n",
        "        -1.15223907, -0.20748713, -0.26374853, -1.38338996, -0.60422153,\n",
        "        -0.6807668 , -0.49697651, -1.76927614, -1.07011443, -2.13637377,\n",
        "        -0.97815482, -1.38615705,  0.16678405, -0.20236665, -0.52664181,\n",
        "        -0.52065308, -1.06395708, -0.09375681],\n",
        "       [ 1.29534095,  0.70877882,  0.22482794, -1.4081337 , -0.63963762,\n",
        "         0.70944757, -0.21818498, -0.87909018,  0.23087154,  1.26274235,\n",
        "         0.23315878, -1.08721924,  0.46586729, -0.64121136, -0.844737  ,\n",
        "        -0.18690388, -0.71034608, -0.98534397,  0.18144543, -0.8120575 ,\n",
        "         0.00244075, -0.28833748,  1.3720753 ,  0.34245524,  1.1515264 ,\n",
        "         1.11200279,  0.38977343,  0.3943303 ]]).T\n",
        "\n",
        "X_test_1 = np.array([[ 1.21290648,  0.60647149,  1.21197796,  1.54724686,  1.00972903,\n",
        "         0.56216029,  0.72973515,  0.39284694,  0.17336897,  0.74244925,\n",
        "         0.6168276 ,  0.91094238,  0.75389832,  1.22221484,  0.60651985,\n",
        "         0.54111179,  0.91559423,  0.25201646],\n",
        "       [-0.71869421, -1.12772433, -0.58861397, -0.0145585 , -1.45496704,\n",
        "        -1.37186247,  0.35988092,  1.00862714,  0.30279016,  2.55054793,\n",
        "         2.28438069, -0.35502465, -0.9418674 ,  0.89477983, -1.14724826,\n",
        "        -0.7799858 ,  1.06303296, -0.55712765]]).T\n",
        "\n",
        "Y_test_1 = np.array([[-1.19236589, -1.10995069,  0.37669071, -0.95531888, -0.89232474,\n",
        "        -0.02095101, -0.29050649, -0.37881187, -0.99739798, -1.20639358,\n",
        "        -0.54710686, -0.25815146, -1.136852  , -0.99897624, -0.78183458,\n",
        "         0.21608231, -1.39421902, -0.85569085, -0.25452413, -2.08591412,\n",
        "        -0.7539892 , -0.49801935],\n",
        "       [-1.09011136,  1.87167148, -1.63772617, -0.20106049, -1.30309817,\n",
        "         1.05833253, -0.04721317, -1.6502976 , -0.36833975, -1.2191319 ,\n",
        "        -0.75123888,  0.43614121, -0.09030079, -1.32835851, -0.10259796,\n",
        "        -0.04046664,  0.06085472,  0.119087  ,  0.81613417, -0.55277698,\n",
        "        -1.03559666,  0.55011099]]).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr1_keJoyZDp"
      },
      "source": [
        "### Dataset 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8DN5S9Kkyboy"
      },
      "outputs": [],
      "source": [
        "# Dataset 2. DO NOT CHANGE THE NUMBERS\n",
        "import numpy as np\n",
        "X_train_2 = np.array([[-1.614901  ,  0.28714288, -1.58856523, -0.62398345, -1.24054186,\n",
        "         1.3540726 , -1.8376991 , -0.76542848,  1.01551298,  1.56603302,\n",
        "        -1.03332383, -0.65191468,  0.08107311,  1.1886501 ,  1.55395519,\n",
        "         1.85121256, -0.38917117,  1.60296587, -1.29848704,  0.8441058 ,\n",
        "         1.51105349,  1.30539824, -1.78357771, -0.07797286, -1.94890625,\n",
        "        -0.67010608,  1.26205438, -0.64744794,  1.49213191, -1.32792377,\n",
        "         0.40606432,  1.1654875 , -1.39691976, -1.53382165],\n",
        "       [-0.74107291,  2.0226272 , -0.80311089, -1.93652965,  0.93944489,\n",
        "        -0.76972033,  0.4438167 , -1.28950516, -0.54197248, -0.68859753,\n",
        "         0.84952455, -1.46468159,  0.89980228, -0.73998096, -1.24199011,\n",
        "        -0.004975  ,  1.22250794,  0.6042052 , -0.09834692,  1.90774378,\n",
        "         1.21666545, -1.52465769,  1.46776645, -1.48563138,  0.92646412,\n",
        "        -2.35182561,  1.08872015,  1.50066709,  1.54360638,  0.08300261,\n",
        "         1.46244545,  0.42036718, -1.16291727,  1.21058973]]).T\n",
        "\n",
        "Y_train_2 = np.array([[ 0.33752225,  0.26007797, -0.77360943, -0.80707957, -1.02059109,\n",
        "         1.21402308, -1.05628487, -0.44228055, -0.40975282, -0.58552875,\n",
        "         0.73242037,  0.60985187, -0.38448676, -1.10713613,  0.71019777,\n",
        "         0.42445554,  0.54032669,  0.16261397, -0.7642942 , -0.0826362 ,\n",
        "        -0.01755153, -1.33428073, -0.05495925,  0.971422  , -0.11024436,\n",
        "         0.46940181],\n",
        "       [ 0.1972156 , -0.40692781, -0.21251355, -0.38086556,  0.55460174,\n",
        "        -0.00750315, -0.08248651,  0.79141975, -0.76573106,  0.28460164,\n",
        "         0.75396732,  0.23217386,  0.97141896, -0.63721127,  0.41754396,\n",
        "        -1.47865265, -0.11135927, -0.18183213, -0.03324034,  0.56319091,\n",
        "        -0.84912994,  0.28134522,  0.52742495, -0.26947631,  0.44022805,\n",
        "         0.77060324]]).T\n",
        "\n",
        "X_test_2 = np.array([[-1.18919052,  1.86146486,  0.73290109, -1.02598963, -1.94986405,\n",
        "         1.98413584, -0.22543794,  1.6738425 , -0.54083103,  0.23855336,\n",
        "         0.29067775,  0.90452835, -0.7807143 ,  0.92563898,  0.5891893 ,\n",
        "        -1.8506076 ],\n",
        "       [ 1.01734226,  1.22983793, -1.32784027, -1.25200345, -1.11164531,\n",
        "         0.11500191,  1.37788957, -0.04001507, -1.45583732,  1.64623486,\n",
        "        -1.5711447 , -1.27852394,  1.32218203,  1.77824856, -1.83015366,\n",
        "        -1.32219896]]).T\n",
        "\n",
        "Y_test_2 = np.array([[ 0.44030401, -0.96934769,  0.83688707,  0.42107823, -0.64710246,\n",
        "        -0.80688878, -0.17615909, -0.07870086,  0.37287753,  1.24256423,\n",
        "        -0.07644516,  0.91728516,  1.4185267 , -0.57032662,  0.32910968,\n",
        "        -0.62365553,  0.04200134, -0.05018494, -0.25026012,  0.30984256,\n",
        "         0.13336253,  0.92133881, -0.76288057,  0.45065785],\n",
        "       [ 0.9436088 , -0.72879255, -0.54252464, -0.95075636, -0.13248588,\n",
        "        -0.59037888,  1.37253857,  0.75478021, -0.65673396, -0.31060961,\n",
        "         0.37673711,  0.94192255, -0.24612582,  0.90276183, -0.88489523,\n",
        "         0.05975249, -1.13783772, -0.72226809,  0.80242032,  0.47174672,\n",
        "        -0.8985866 ,  0.59402413, -0.07023891, -0.97869024]]).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8-nQi54xtXD"
      },
      "source": [
        "### Dataset 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EqfuVu9Gyd17"
      },
      "outputs": [],
      "source": [
        "# Dataset 3. DO NOT CHANGE THE NUMBERS\n",
        "import numpy as np\n",
        "X_train_3 = np.array([[ 0.30920485,  0.74779523, -1.19805934, -1.4065875 ,  0.81773837,\n",
        "        -1.30667592, -0.22120141,  0.07813527, -0.42443599,  0.03138162,\n",
        "        -2.02716273, -0.20216417, -1.77093289,  0.19895122,  0.27524467,\n",
        "        -0.9843448 , -0.31251963, -1.72018154, -2.05161935, -0.81445041,\n",
        "         0.75566503, -1.61181827,  0.24942261,  0.43094924,  0.26285439,\n",
        "        -1.49128776, -1.2378428 ,  0.15350841, -1.63601617, -0.03734756,\n",
        "        -0.22413227],\n",
        "       [-0.127041  ,  0.54957438,  1.40047603, -1.03687185,  1.64300265,\n",
        "        -0.60711187,  1.00868763,  0.18433247,  1.30854456,  1.27867747,\n",
        "        -0.07552655,  0.09829492, -0.15602456,  2.27694191,  0.58976897,\n",
        "         1.29546509,  1.85361272, -0.11323539,  0.3295589 ,  0.03881959,\n",
        "         0.62671139, -1.16122353,  0.37041953, -0.51610516,  0.08970487,\n",
        "         0.68265883,  0.7264372 ,  0.8912278 ,  1.14409337,  0.53962298,\n",
        "         0.94477311]]).T\n",
        "\n",
        "Y_train_3 = np.array([[-0.48691402,  0.50954902,  1.35242892,  1.89600064, -0.33075371,\n",
        "        -0.62663858, -0.85151619, -0.59739923,  0.15581821,  0.24130156,\n",
        "         0.0081454 ,  1.01975478,  1.22467352,  0.51038341,  0.88796385,\n",
        "         0.15940018, -0.1636123 ,  1.53916295, -0.6851801 , -0.42081847,\n",
        "        -0.36004546,  1.10877664,  1.82124821, -0.04156698,  0.23092986,\n",
        "         1.85584796, -0.34194837,  0.89063568, -0.99471418],\n",
        "       [ 0.57259859, -1.66427178,  0.60859541, -0.42653506, -0.55325533,\n",
        "        -0.45097084, -0.06022663,  0.27829883, -1.14573741, -1.74371889,\n",
        "        -0.58656254, -0.39964896, -1.45537741, -1.09925804, -1.22007405,\n",
        "        -1.05506347, -1.53782127, -0.40646646,  0.56462893, -1.03126372,\n",
        "         0.03132026, -0.56596703, -0.46607732, -0.71850484, -1.16563865,\n",
        "         0.39711336, -0.50298565, -0.73843955, -0.7858591 ]]).T\n",
        "\n",
        "X_test_3 = np.array([[-1.55182484, -1.14359579, -0.28724359,  0.4860189 ,  0.59348201,\n",
        "         0.20764271, -0.71978547, -0.52880272, -0.83190068, -0.17344159,\n",
        "         0.11892081, -1.55268459, -0.97786341,  1.15004209, -1.55962329,\n",
        "        -0.98048598, -0.73153577, -0.75993791, -0.22465612],\n",
        "       [ 0.46910804,  0.76280671,  1.0525906 ,  1.96041925,  0.25278868,\n",
        "         0.88856402,  1.72334673,  1.28542054,  0.93244079,  1.50362044,\n",
        "         0.14210094, -0.3087488 ,  1.51041733, -0.46423271, -0.26480295,\n",
        "         0.8478617 ,  1.24236135,  1.31112526,  1.70271788]]).T\n",
        "\n",
        "Y_test_3 = np.array([[ 0.59260113, -0.87894137, -0.02974639,  1.7173351 , -0.09130345,\n",
        "         1.31650323,  0.3712312 ,  1.39730283,  1.12756772,  0.62682189,\n",
        "        -0.34408365,  1.33380816,  1.89457786, -0.31784745,  1.37086214,\n",
        "         1.69531142, -0.53631325,  1.60097254,  0.98840214,  1.81872078,\n",
        "         0.67050908],\n",
        "       [-1.44842808,  0.65349306, -0.63475756, -0.17875463, -0.93824346,\n",
        "        -1.10788814, -1.30192489,  0.39040035, -1.65289561, -2.14337167,\n",
        "        -0.11501714, -0.73018114, -1.57392425, -1.493817  ,  0.22375044,\n",
        "        -0.91174565, -0.20549059, -0.09531556, -1.75933045,  0.7346544 ,\n",
        "        -1.01221609]]).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgaT8uzm_ZqC"
      },
      "source": [
        "### Dataset 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Q3k-UyP6_b-J"
      },
      "outputs": [],
      "source": [
        "# Dataset 4. DO NOT CHANGE THE NUMBERS\n",
        "import numpy as np\n",
        "X_4 = np.array([[ 3.496052,  4.042794,  2.79643 ,  5.085416,  4.240754,  3.737034,\n",
        "         3.343466,  3.786328,  4.965464,  3.826312,  4.208512,  4.620014,\n",
        "         3.242036,  5.14892 ,  2.50782 ,  3.528098,  4.719288,  5.184396,\n",
        "         5.086984,  3.900596],\n",
        "       [-2.938138,  0.507444,  2.100728, -0.066346,  0.308112,  1.280272,\n",
        "         3.851106,  0.200998,  0.104566, -1.468236, -2.356998,  2.863952,\n",
        "         1.513512, -2.811326,  1.007538,  1.21716 ,  1.255772,  1.17943 ,\n",
        "        -2.121112, -0.276458]]).T\n",
        "\n",
        "Y_4 = np.array([[-4.47517 , -3.616592, -3.222338, -1.616118, -5.363638, -3.54466 ,\n",
        "        -1.163848, -1.032822, -1.36367 , -1.990576, -1.959902, -0.24304 ,\n",
        "        -1.288602, -0.81389 , -1.89679 , -1.068004, -2.55192 , -4.272996,\n",
        "        -1.77429 ,  0.303408],\n",
        "       [ 2.363466,  4.178916,  2.78908 ,  0.5145  ,  1.867194,  2.923438,\n",
        "         4.613742,  0.950796,  0.377692,  1.884344,  1.461572, -0.978432,\n",
        "         3.36434 ,  2.866108,  3.021634,  1.55918 ,  1.496068,  1.593088,\n",
        "         2.453626,  1.409632]]).T\n",
        "\n",
        "Z_4 = np.array([[ 1.710198,  2.58181 ,  0.581826, -2.765266,  2.969792,  1.069866,\n",
        "        -1.743714,  1.217356,  2.143554, -2.254784, -3.259284,  2.706466,\n",
        "         0.898268,  0.058898, -2.59896 , -3.25409 ,  4.040442, -3.34033 ,\n",
        "        -3.096212, -0.716478],\n",
        "       [-3.13698 , -4.892258, -3.686858, -4.64716 , -4.04887 , -3.83376 ,\n",
        "        -4.468408, -4.850902, -3.36238 , -4.180288, -6.078254, -4.428228,\n",
        "        -3.690582, -4.903822, -4.286912, -4.954782, -3.865414, -3.960376,\n",
        "        -5.242314, -2.98557 ]]).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddSAbCan06No"
      },
      "source": [
        "# Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRRUhcLwy2Ra"
      },
      "source": [
        "0.   Read Section $8.6$ of $[1]$.\n",
        "1.   For dataset $1$, determine a standard support vector classifier with $\\gamma = 0.1$ (notation from Section $8.6$ of the book). Plot the points, the classifier $f$ and the associated slab. **[10 marks]**\n",
        "\n",
        "2.   Use the test set to assess how good the classifier is on unseen data. To this end, first define a \"metric\" (or more than one if you prefer) which numerically quantifies how good or bad a classifier is. Explain why you picked this metric and how the metric works. **[10 marks]**\n",
        "\n",
        "3.   Discuss, possibly with the help of figures, the role of the parameter $\\gamma$ and find for which $\\gamma$ (or $\\gamma$'s) your classifier behaves best on the test set. **[10 marks]**\n",
        "\n",
        "4.   Now determine a linear classifier by approximating it via logistic modeling. Compare and discuss the results with those obtained in parts 1. 2. and 3. **[10 marks]**\n",
        "\n",
        "5.   For dataset $2$, determine a standard support vector classifier with $\\gamma=0.1$. Plot the points, the classifier $f$ and the associated slab. Score your classifier on the test set using your metric. **[5 marks]**\n",
        "\n",
        "6.   Implement nonlinear classifiers for dataset $2$. There are many options here. Discuss as much as you can and try to find the best classifier among those which are obtainable by means of convex optimisation. The more details you provide to explain how you reached your final choice, the better. **[25 marks]**\n",
        "\n",
        "7.   Repeat parts 5. and 6. on dataset 3. **[15 marks]**\n",
        "\n",
        "8.   Dataset $4$ consists of three sets of points corresponding to three classes instead of two. Explain how you would go about finding a classifier for this case. Try to find a classifier and plot the points and the classifiers. Describe your results. **[15 marks]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normal vector a: [ 1.32003818 -0.17034156]\n",
            "Offset b: -0.03907326256830654\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cvxpy as cp\n",
        "\n",
        "# Define the standard support vector classifier function\n",
        "def standard_svm(X, Y, gamma=0.1):\n",
        "    \"\"\"\n",
        "    Implement a standard support vector classifier\n",
        "    \n",
        "    Parameters:\n",
        "    X: Training data points (n_samples, n_features)\n",
        "    Y: Training data points of the other class (m_samples, n_features)\n",
        "    gamma: Parameter controlling the trade-off between margin and misclassification\n",
        "    \n",
        "    Returns:\n",
        "    a: Normal vector to the separating hyperplane\n",
        "    b: Offset of the hyperplane\n",
        "    \"\"\"\n",
        "    n, d = X.shape  # n samples, d features for X\n",
        "    m, _ = Y.shape  # m samples for Y\n",
        "    \n",
        "    # Define the optimization variables\n",
        "    a = cp.Variable(d)  # normal vector to the separating hyperplane\n",
        "    b = cp.Variable()   # offset\n",
        "    xi = cp.Variable(n)  # slack variables for X\n",
        "    eta = cp.Variable(m)  # slack variables for Y\n",
        "    \n",
        "    # Define the objective function\n",
        "    objective = cp.Minimize(cp.norm(a, 2) + gamma * (cp.sum(xi) + cp.sum(eta)))\n",
        "    \n",
        "    # Define the constraints\n",
        "    constraints = [\n",
        "        cp.multiply(X @ a - b, np.ones(n)) >= 1 - xi,  # X should be on the positive side\n",
        "        cp.multiply(Y @ a - b, np.ones(m)) <= -1 + eta,  # Y should be on the negative side\n",
        "        xi >= 0,  # slack variables are non-negative\n",
        "        eta >= 0  # slack variables are non-negative\n",
        "    ]\n",
        "    \n",
        "    # Solve the problem\n",
        "    problem = cp.Problem(objective, constraints)\n",
        "    problem.solve()\n",
        "    \n",
        "    return a.value, b.value\n",
        "\n",
        "# Apply the standard SVM to dataset 1\n",
        "a_1, b_1 = standard_svm(X_train_1, Y_train_1, gamma=0.1)\n",
        "\n",
        "print(\"Normal vector a:\", a_1)\n",
        "print(\"Offset b:\", b_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Function to plot the data points and the classifier\n",
        "def plot_classifier(X, Y, a, b, title=\"Support Vector Classifier\"):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    \n",
        "    # Plot the data points\n",
        "    plt.scatter(X[:, 0], X[:, 1], c='blue', label='Class X')\n",
        "    plt.scatter(Y[:, 0], Y[:, 1], c='red', label='Class Y')\n",
        "    \n",
        "    # Plot the decision boundary (hyperplane)\n",
        "    x_min, x_max = min(np.min(X[:, 0]), np.min(Y[:, 0])) - 0.5, max(np.max(X[:, 0]), np.max(Y[:, 0])) + 0.5\n",
        "    y_min, y_max = min(np.min(X[:, 1]), np.min(Y[:, 1])) - 0.5, max(np.max(X[:, 1]), np.max(Y[:, 1])) + 0.5\n",
        "    \n",
        "    # Create a grid of points\n",
        "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
        "                         np.linspace(y_min, y_max, 100))\n",
        "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
        "    \n",
        "    # Compute the decision function values\n",
        "    Z = grid @ a - b\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    \n",
        "    # Plot the decision boundary and margins\n",
        "    plt.contour(xx, yy, Z, levels=[-1, 0, 1], colors=['r', 'k', 'b'], linestyles=['--', '-', '--'])\n",
        "    \n",
        "    # Fill the regions\n",
        "    plt.contourf(xx, yy, Z, levels=[-100, -1, 1, 100], colors=['#FFAAAA', '#FFFFFF', '#AAAAFF'], alpha=0.3)\n",
        "    \n",
        "    plt.title(title)\n",
        "    plt.xlabel('Feature 1')\n",
        "    plt.ylabel('Feature 2')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Plot the classifier for dataset 1 (training data)\n",
        "plot_classifier(X_train_1, Y_train_1, a_1, b_1, title=\"Standard SVM Classifier for Dataset 1 (γ=0.1) - Training Data\")\n",
        "\n",
        "# Plot the classifier for dataset 1 (test data)\n",
        "plot_classifier(X_test_1, Y_test_1, a_1, b_1, title=\"Standard SVM Classifier for Dataset 1 (γ=0.1) - Test Data\")\n",
        "\n",
        "# Evaluate the classifier on training data\n",
        "def evaluate_points(X, Y, a, b):\n",
        "    \"\"\"\n",
        "    Evaluate how many points are correctly classified\n",
        "    \n",
        "    Parameters:\n",
        "    X: Data points expected to be on the positive side\n",
        "    Y: Data points expected to be on the negative side\n",
        "    a: Normal vector to the separating hyperplane\n",
        "    b: Offset of the hyperplane\n",
        "    \n",
        "    Returns:\n",
        "    X_correct: Number of correctly classified X points\n",
        "    Y_correct: Number of correctly classified Y points\n",
        "    \"\"\"\n",
        "    X_predictions = X @ a - b\n",
        "    Y_predictions = Y @ a - b\n",
        "    \n",
        "    X_correct = np.sum(X_predictions > 0)\n",
        "    Y_correct = np.sum(Y_predictions < 0)\n",
        "    \n",
        "    return X_correct, Y_correct\n",
        "\n",
        "# Evaluate on training data\n",
        "X_correct_train, Y_correct_train = evaluate_points(X_train_1, Y_train_1, a_1, b_1)\n",
        "print(f\"Training data - Correctly classified X points: {X_correct_train}/{len(X_train_1)} ({X_correct_train/len(X_train_1)*100:.2f}%)\")\n",
        "print(f\"Training data - Correctly classified Y points: {Y_correct_train}/{len(Y_train_1)} ({Y_correct_train/len(Y_train_1)*100:.2f}%)\")\n",
        "print(f\"Training data - Overall accuracy: {(X_correct_train + Y_correct_train)/(len(X_train_1) + len(Y_train_1))*100:.2f}%\")\n",
        "\n",
        "# Evaluate on test data\n",
        "X_correct_test, Y_correct_test = evaluate_points(X_test_1, Y_test_1, a_1, b_1)\n",
        "print(f\"Test data - Correctly classified X points: {X_correct_test}/{len(X_test_1)} ({X_correct_test/len(X_test_1)*100:.2f}%)\")\n",
        "print(f\"Test data - Correctly classified Y points: {Y_correct_test}/{len(Y_test_1)} ({Y_correct_test/len(Y_test_1)*100:.2f}%)\")\n",
        "print(f\"Test data - Overall accuracy: {(X_correct_test + Y_correct_test)/(len(X_test_1) + len(Y_test_1))*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performance Metrics for Standard SVM Classifier (γ=0.1) on Test Set:\n",
            "Accuracy: 0.9500\n",
            "Precision: 0.9000\n",
            "Recall: 1.0000\n",
            "Specificity: 0.9091\n",
            "F1 Score: 0.9474\n",
            "Balanced Accuracy: 0.9545\n",
            "Misclassification Rate: 0.0500\n",
            "Geometric Mean: 0.9535\n",
            "Confusion Matrix:\n",
            "TP: 18, FP: 2\n",
            "FN: 0, TN: 20\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"\\nI've chosen several metrics to evaluate the classifier:\\n\\n1. Accuracy: The proportion of correctly classified samples out of all samples. It gives an overall measure of the classifier's performance.\\n   - Formula: (TP + TN) / (TP + TN + FP + FN)\\n   - Pros: Simple and intuitive\\n   - Cons: Can be misleading with imbalanced classes\\n\\n2. Precision: The proportion of true positives out of all predicted positives. It measures how many of the points classified as X are actually X.\\n   - Formula: TP / (TP + FP)\\n   - Pros: Important when the cost of false positives is high\\n   - Cons: Doesn't consider false negatives\\n\\n3. Recall (Sensitivity): The proportion of true positives out of all actual positives. It measures how many of the actual X points are correctly classified.\\n   - Formula: TP / (TP + FN)\\n   - Pros: Important when the cost of false negatives is high\\n   - Cons: Doesn't consider false positives\\n\\n4. Specificity: The proportion of true negatives out of all actual negatives. It measures how many of the actual Y points are correctly classified.\\n   - Formula: TN / (TN + FP)\\n   - Pros: Complements recall by focusing on the negative class\\n   - Cons: Doesn't consider false negatives\\n\\n5. F1 Score: The harmonic mean of precision and recall. It provides a balance between precision and recall.\\n   - Formula: 2 * (precision * recall) / (precision + recall)\\n   - Pros: Combines precision and recall into a single metric\\n   - Cons: Doesn't consider true negatives\\n\\n6. Balanced Accuracy: The average of recall and specificity. It's useful when classes are imbalanced.\\n   - Formula: (recall + specificity) / 2\\n   - Pros: Accounts for both classes equally, regardless of their sizes\\n   - Cons: May not reflect overall performance if one class is more important\\n\\n7. Misclassification Rate: The proportion of incorrect predictions. It's the complement of accuracy.\\n   - Formula: 1 - accuracy\\n   - Pros: Directly measures the error rate\\n   - Cons: Same limitations as accuracy\\n\\n8. Geometric Mean: The square root of the product of recall and specificity. It's another way to balance the performance on both classes.\\n   - Formula: sqrt(recall * specificity)\\n   - Pros: Penalizes poor performance on either class\\n   - Cons: Less intuitive than some other metrics\\n\\nThese metrics were chosen because they provide a comprehensive evaluation of the classifier's performance. Different metrics focus on different aspects of classification performance:\\n- Accuracy gives an overall view but can be misleading with imbalanced classes.\\n- Precision and recall focus on the positive class from different angles.\\n- Specificity focuses on the negative class.\\n- F1 score, balanced accuracy, and geometric mean provide balanced measures that consider both classes.\\n\\nBy examining all these metrics together, we get a more complete picture of how well the classifier is performing on both classes, which is especially important when the classes are imbalanced or when the costs of different types of errors vary.\\n\""
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 2. Evaluating the Classifier on Test Data\n",
        "\n",
        "# Define a more comprehensive evaluation function\n",
        "def evaluate_classifier(X_test, Y_test, a, b):\n",
        "    \"\"\"\n",
        "    Evaluate the classifier on test data with multiple metrics\n",
        "    \n",
        "    Parameters:\n",
        "    X_test: Test data points of class X\n",
        "    Y_test: Test data points of class Y\n",
        "    a: Normal vector to the separating hyperplane\n",
        "    b: Offset of the hyperplane\n",
        "    \n",
        "    Returns:\n",
        "    metrics: Dictionary containing various performance metrics\n",
        "    \"\"\"\n",
        "    # Combine test data\n",
        "    X_predictions = X_test @ a - b\n",
        "    Y_predictions = Y_test @ a - b\n",
        "    \n",
        "    # Count correct predictions\n",
        "    X_correct = np.sum(X_predictions > 0)\n",
        "    Y_correct = np.sum(Y_predictions < 0)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    total_samples = len(X_test) + len(Y_test)\n",
        "    \n",
        "    # True positives: X points correctly classified as X\n",
        "    TP = X_correct\n",
        "    # False positives: Y points incorrectly classified as X\n",
        "    FP = len(Y_test) - Y_correct\n",
        "    # True negatives: Y points correctly classified as Y\n",
        "    TN = Y_correct\n",
        "    # False negatives: X points incorrectly classified as Y\n",
        "    FN = len(X_test) - X_correct\n",
        "    \n",
        "    # Accuracy: Overall proportion of correct predictions\n",
        "    accuracy = (TP + TN) / total_samples\n",
        "    \n",
        "    # Precision: Proportion of true positives among all positive predictions\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "    \n",
        "    # Recall (Sensitivity): Proportion of true positives among all actual positives\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "    \n",
        "    # Specificity: Proportion of true negatives among all actual negatives\n",
        "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
        "    \n",
        "    # F1 Score: Harmonic mean of precision and recall\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    \n",
        "    # Balanced Accuracy: Average of recall and specificity\n",
        "    balanced_accuracy = (recall + specificity) / 2\n",
        "    \n",
        "    # Misclassification Rate: Proportion of incorrect predictions\n",
        "    misclassification_rate = 1 - accuracy\n",
        "    \n",
        "    # Geometric Mean: Square root of the product of recall and specificity\n",
        "    g_mean = np.sqrt(recall * specificity)\n",
        "    \n",
        "    # Store all metrics in a dictionary\n",
        "    metrics = {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'specificity': specificity,\n",
        "        'f1_score': f1_score,\n",
        "        'balanced_accuracy': balanced_accuracy,\n",
        "        'misclassification_rate': misclassification_rate,\n",
        "        'g_mean': g_mean,\n",
        "        'TP': TP,\n",
        "        'FP': FP,\n",
        "        'TN': TN,\n",
        "        'FN': FN\n",
        "    }\n",
        "    \n",
        "    return metrics\n",
        "\n",
        "# Evaluate the classifier on the test set\n",
        "metrics_1 = evaluate_classifier(X_test_1, Y_test_1, a_1, b_1)\n",
        "\n",
        "# Print the metrics\n",
        "print(\"Performance Metrics for Standard SVM Classifier (γ=0.1) on Test Set:\")\n",
        "print(f\"Accuracy: {metrics_1['accuracy']:.4f}\")\n",
        "print(f\"Precision: {metrics_1['precision']:.4f}\")\n",
        "print(f\"Recall: {metrics_1['recall']:.4f}\")\n",
        "print(f\"Specificity: {metrics_1['specificity']:.4f}\")\n",
        "print(f\"F1 Score: {metrics_1['f1_score']:.4f}\")\n",
        "print(f\"Balanced Accuracy: {metrics_1['balanced_accuracy']:.4f}\")\n",
        "print(f\"Misclassification Rate: {metrics_1['misclassification_rate']:.4f}\")\n",
        "print(f\"Geometric Mean: {metrics_1['g_mean']:.4f}\")\n",
        "print(f\"Confusion Matrix:\")\n",
        "print(f\"TP: {metrics_1['TP']}, FP: {metrics_1['FP']}\")\n",
        "print(f\"FN: {metrics_1['FN']}, TN: {metrics_1['TN']}\")\n",
        "\n",
        "# Explanation of the chosen metrics\n",
        "\"\"\"\n",
        "I've chosen several metrics to evaluate the classifier:\n",
        "\n",
        "1. Accuracy: The proportion of correctly classified samples out of all samples. It gives an overall measure of the classifier's performance.\n",
        "   - Formula: (TP + TN) / (TP + TN + FP + FN)\n",
        "   - Pros: Simple and intuitive\n",
        "   - Cons: Can be misleading with imbalanced classes\n",
        "\n",
        "2. Precision: The proportion of true positives out of all predicted positives. It measures how many of the points classified as X are actually X.\n",
        "   - Formula: TP / (TP + FP)\n",
        "   - Pros: Important when the cost of false positives is high\n",
        "   - Cons: Doesn't consider false negatives\n",
        "\n",
        "3. Recall (Sensitivity): The proportion of true positives out of all actual positives. It measures how many of the actual X points are correctly classified.\n",
        "   - Formula: TP / (TP + FN)\n",
        "   - Pros: Important when the cost of false negatives is high\n",
        "   - Cons: Doesn't consider false positives\n",
        "\n",
        "4. Specificity: The proportion of true negatives out of all actual negatives. It measures how many of the actual Y points are correctly classified.\n",
        "   - Formula: TN / (TN + FP)\n",
        "   - Pros: Complements recall by focusing on the negative class\n",
        "   - Cons: Doesn't consider false negatives\n",
        "\n",
        "5. F1 Score: The harmonic mean of precision and recall. It provides a balance between precision and recall.\n",
        "   - Formula: 2 * (precision * recall) / (precision + recall)\n",
        "   - Pros: Combines precision and recall into a single metric\n",
        "   - Cons: Doesn't consider true negatives\n",
        "\n",
        "6. Balanced Accuracy: The average of recall and specificity. It's useful when classes are imbalanced.\n",
        "   - Formula: (recall + specificity) / 2\n",
        "   - Pros: Accounts for both classes equally, regardless of their sizes\n",
        "   - Cons: May not reflect overall performance if one class is more important\n",
        "\n",
        "7. Misclassification Rate: The proportion of incorrect predictions. It's the complement of accuracy.\n",
        "   - Formula: 1 - accuracy\n",
        "   - Pros: Directly measures the error rate\n",
        "   - Cons: Same limitations as accuracy\n",
        "\n",
        "8. Geometric Mean: The square root of the product of recall and specificity. It's another way to balance the performance on both classes.\n",
        "   - Formula: sqrt(recall * specificity)\n",
        "   - Pros: Penalizes poor performance on either class\n",
        "   - Cons: Less intuitive than some other metrics\n",
        "\n",
        "These metrics were chosen because they provide a comprehensive evaluation of the classifier's performance. Different metrics focus on different aspects of classification performance:\n",
        "- Accuracy gives an overall view but can be misleading with imbalanced classes.\n",
        "- Precision and recall focus on the positive class from different angles.\n",
        "- Specificity focuses on the negative class.\n",
        "- F1 score, balanced accuracy, and geometric mean provide balanced measures that consider both classes.\n",
        "\n",
        "By examining all these metrics together, we get a more complete picture of how well the classifier is performing on both classes, which is especially important when the classes are imbalanced or when the costs of different types of errors vary.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Q4\n",
        "\n",
        "def test_gamma_values(X_train, Y_train, X_test, Y_test, gamma_values):\n",
        "    \"\"\"\n",
        "    Test different values of gamma and evaluate their performance\n",
        "    \n",
        "    Parameters:\n",
        "    X_train: Training data points of class X\n",
        "    Y_train: Training data points of class Y\n",
        "    X_test: Test data points of class X\n",
        "    Y_test: Test data points of class Y\n",
        "    gamma_values: List of gamma values to test\n",
        "    \n",
        "    Returns:\n",
        "    results: List of tuples (gamma, metrics) for each gamma value\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    \n",
        "    for gamma in gamma_values:\n",
        "        # Train the classifier with the current gamma\n",
        "        a, b = standard_svm(X_train, Y_train, gamma=gamma)\n",
        "        \n",
        "        # Evaluate on test data\n",
        "        metrics = evaluate_classifier(X_test, Y_test, a, b)\n",
        "        \n",
        "        # Store the results\n",
        "        results.append((gamma, a, b, metrics))\n",
        "        \n",
        "        # Plot the classifier for each gamma\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plot_classifier(X_train, Y_train, a, b, title=f\"SVM Classifier with γ={gamma} - Training Data\")\n",
        "        \n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plot_classifier(X_test, Y_test, a, b, title=f\"SVM Classifier with γ={gamma} - Test Data\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Define a range of gamma values to test\n",
        "gamma_values = [0.001, 0.01, 0.1, 1, 10, 100]\n",
        "\n",
        "# Test the different gamma values\n",
        "results = test_gamma_values(X_train_1, Y_train_1, X_test_1, Y_test_1, gamma_values)\n",
        "\n",
        "# Extract the metrics for plotting\n",
        "gamma_values = [result[0] for result in results]\n",
        "accuracies = [result[3]['accuracy'] for result in results]\n",
        "precisions = [result[3]['precision'] for result in results]\n",
        "recalls = [result[3]['recall'] for result in results]\n",
        "specificities = [result[3]['specificity'] for result in results]\n",
        "f1_scores = [result[3]['f1_score'] for result in results]\n",
        "balanced_accuracies = [result[3]['balanced_accuracy'] for result in results]\n",
        "g_means = [result[3]['g_mean'] for result in results]\n",
        "\n",
        "# Plot the metrics vs gamma\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.semilogx(gamma_values, accuracies, 'o-', label='Accuracy')\n",
        "plt.semilogx(gamma_values, precisions, 's-', label='Precision')\n",
        "plt.semilogx(gamma_values, recalls, '^-', label='Recall')\n",
        "plt.semilogx(gamma_values, specificities, 'v-', label='Specificity')\n",
        "plt.semilogx(gamma_values, f1_scores, 'd-', label='F1 Score')\n",
        "plt.semilogx(gamma_values, balanced_accuracies, '*-', label='Balanced Accuracy')\n",
        "plt.semilogx(gamma_values, g_means, 'x-', label='G-Mean')\n",
        "\n",
        "plt.xlabel('γ (log scale)')\n",
        "plt.ylabel('Metric Value')\n",
        "plt.title('Classifier Performance vs γ')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Find the best gamma based on different metrics\n",
        "best_gamma_accuracy_idx = np.argmax(accuracies)\n",
        "best_gamma_f1_idx = np.argmax(f1_scores)\n",
        "best_gamma_balanced_accuracy_idx = np.argmax(balanced_accuracies)\n",
        "best_gamma_g_mean_idx = np.argmax(g_means)\n",
        "\n",
        "print(f\"Best γ value based on Accuracy: {gamma_values[best_gamma_accuracy_idx]}\")\n",
        "print(f\"Best γ value based on F1 Score: {gamma_values[best_gamma_f1_idx]}\")\n",
        "print(f\"Best γ value based on Balanced Accuracy: {gamma_values[best_gamma_balanced_accuracy_idx]}\")\n",
        "print(f\"Best γ value based on G-Mean: {gamma_values[best_gamma_g_mean_idx]}\")\n",
        "\n",
        "# Print detailed metrics for the best gamma based on F1 score\n",
        "best_gamma = gamma_values[best_gamma_f1_idx]\n",
        "best_metrics = results[best_gamma_f1_idx][3]\n",
        "\n",
        "print(f\"\\nDetailed metrics for best γ={best_gamma} (based on F1 Score):\")\n",
        "print(f\"Accuracy: {best_metrics['accuracy']:.4f}\")\n",
        "print(f\"Precision: {best_metrics['precision']:.4f}\")\n",
        "print(f\"Recall: {best_metrics['recall']:.4f}\")\n",
        "print(f\"Specificity: {best_metrics['specificity']:.4f}\")\n",
        "print(f\"F1 Score: {best_metrics['f1_score']:.4f}\")\n",
        "print(f\"Balanced Accuracy: {best_metrics['balanced_accuracy']:.4f}\")\n",
        "print(f\"G-Mean: {best_metrics['g_mean']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normal vector a: [1.24894411e-10 4.79227615e-11]\n",
            "Offset b: -0.9999999993240452\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Performance Metrics for Standard SVM Classifier (γ=0.1) on Dataset 2 Test Set:\n",
            "Accuracy: 0.4000\n",
            "Precision: 0.4000\n",
            "Recall: 1.0000\n",
            "Specificity: 0.0000\n",
            "F1 Score: 0.5714\n",
            "Balanced Accuracy: 0.5000\n",
            "Misclassification Rate: 0.6000\n",
            "Geometric Mean: 0.0000\n",
            "Confusion Matrix:\n",
            "TP: 16, FP: 24\n",
            "FN: 0, TN: 0\n"
          ]
        }
      ],
      "source": [
        "# Apply the standard SVM to dataset 2\n",
        "a_2, b_2 = standard_svm(X_train_2, Y_train_2, gamma=0.1)\n",
        "\n",
        "print(\"Normal vector a:\", a_2)\n",
        "print(\"Offset b:\", b_2)\n",
        "\n",
        "# Plot the classifier for dataset 2 (training data)\n",
        "plot_classifier(X_train_2, Y_train_2, a_2, b_2, title=\"Standard SVM Classifier for Dataset 2 (γ=0.1) - Training Data\")\n",
        "\n",
        "# Plot the classifier for dataset 2 (test data)\n",
        "plot_classifier(X_test_2, Y_test_2, a_2, b_2, title=\"Standard SVM Classifier for Dataset 2 (γ=0.1) - Test Data\")\n",
        "\n",
        "# Evaluate the classifier on the test set using the metrics defined in question 2\n",
        "metrics_2 = evaluate_classifier(X_test_2, Y_test_2, a_2, b_2)\n",
        "\n",
        "# Print the metrics\n",
        "print(\"\\nPerformance Metrics for Standard SVM Classifier (γ=0.1) on Dataset 2 Test Set:\")\n",
        "print(f\"Accuracy: {metrics_2['accuracy']:.4f}\")\n",
        "print(f\"Precision: {metrics_2['precision']:.4f}\")\n",
        "print(f\"Recall: {metrics_2['recall']:.4f}\")\n",
        "print(f\"Specificity: {metrics_2['specificity']:.4f}\")\n",
        "print(f\"F1 Score: {metrics_2['f1_score']:.4f}\")\n",
        "print(f\"Balanced Accuracy: {metrics_2['balanced_accuracy']:.4f}\")\n",
        "print(f\"Misclassification Rate: {metrics_2['misclassification_rate']:.4f}\")\n",
        "print(f\"Geometric Mean: {metrics_2['g_mean']:.4f}\")\n",
        "print(f\"Confusion Matrix:\")\n",
        "print(f\"TP: {metrics_2['TP']}, FP: {metrics_2['FP']}\")\n",
        "print(f\"FN: {metrics_2['FN']}, TN: {metrics_2['TN']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training kernel SVM with Linear kernel...\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Incompatible dimensions (1, 34) (26, 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 274\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining kernel SVM with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkernel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m kernel...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    273\u001b[0m \u001b[38;5;66;03m# Train the kernel SVM\u001b[39;00m\n\u001b[1;32m--> 274\u001b[0m alpha_x, alpha_y, b \u001b[38;5;241m=\u001b[39m kernel_svm(X_train_2, Y_train_2, kernel_func)\n\u001b[0;32m    276\u001b[0m \u001b[38;5;66;03m# Evaluate on test data\u001b[39;00m\n\u001b[0;32m    277\u001b[0m metrics \u001b[38;5;241m=\u001b[39m evaluate_kernel_svm(X_test_2, Y_test_2, X_train_2, Y_train_2, alpha_x, alpha_y, b, kernel_func)\n",
            "Cell \u001b[1;32mIn[12], line 46\u001b[0m, in \u001b[0;36mkernel_svm\u001b[1;34m(X, Y, kernel_func, gamma)\u001b[0m\n\u001b[0;32m     39\u001b[0m alpha_y \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mVariable(m)  \u001b[38;5;66;03m# dual variables for Y\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Define the objective function (dual problem)\u001b[39;00m\n\u001b[0;32m     42\u001b[0m obj \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mMaximize(\n\u001b[0;32m     43\u001b[0m     cp\u001b[38;5;241m.\u001b[39msum(alpha_x) \u001b[38;5;241m+\u001b[39m cp\u001b[38;5;241m.\u001b[39msum(alpha_y) \u001b[38;5;241m-\u001b[39m \n\u001b[0;32m     44\u001b[0m     \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m cp\u001b[38;5;241m.\u001b[39mquad_form(alpha_x, K_xx) \u001b[38;5;241m-\u001b[39m \n\u001b[0;32m     45\u001b[0m     \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m cp\u001b[38;5;241m.\u001b[39mquad_form(alpha_y, K_yy) \u001b[38;5;241m-\u001b[39m \n\u001b[1;32m---> 46\u001b[0m     cp\u001b[38;5;241m.\u001b[39msum(cp\u001b[38;5;241m.\u001b[39mmultiply(alpha_x \u001b[38;5;241m@\u001b[39m alpha_y\u001b[38;5;241m.\u001b[39mT, K_xy))\n\u001b[0;32m     47\u001b[0m )\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Define the constraints\u001b[39;00m\n\u001b[0;32m     50\u001b[0m constraints \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     51\u001b[0m     alpha_x \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     52\u001b[0m     alpha_x \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m gamma,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m     cp\u001b[38;5;241m.\u001b[39msum(alpha_x) \u001b[38;5;241m==\u001b[39m cp\u001b[38;5;241m.\u001b[39msum(alpha_y)\n\u001b[0;32m     56\u001b[0m ]\n",
            "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\cvxpy\\expressions\\expression.py:50\u001b[0m, in \u001b[0;36m_cast_other.<locals>.cast_op\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A wrapped binary operator that can handle non-Expression arguments.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     49\u001b[0m other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcast_to_const(other)\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m binary_op(\u001b[38;5;28mself\u001b[39m, other)\n",
            "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\cvxpy\\expressions\\expression.py:687\u001b[0m, in \u001b[0;36mExpression.__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    684\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcvxpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpressions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcvxtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quad_form\n\u001b[0;32m    685\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m quad_form()(other, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m--> 687\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cvxtypes\u001b[38;5;241m.\u001b[39mmatmul_expr()(\u001b[38;5;28mself\u001b[39m, other)\n",
            "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\cvxpy\\atoms\\affine\\binary_operators.py:51\u001b[0m, in \u001b[0;36mBinaryOperator.__init__\u001b[1;34m(self, lh_exp, rh_exp)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lh_exp, rh_exp) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28msuper\u001b[39m(BinaryOperator, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(lh_exp, rh_exp)\n",
            "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\cvxpy\\atoms\\atom.py:51\u001b[0m, in \u001b[0;36mAtom.__init__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m [Atom\u001b[38;5;241m.\u001b[39mcast_to_const(arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_arguments()\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_from_args()\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s\u001b[38;5;241m.\u001b[39mALLOW_ND_EXPR \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAtoms must be at most 2D.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\cvxpy\\atoms\\affine\\binary_operators.py:121\u001b[0m, in \u001b[0;36mMulExpression.shape_from_args\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshape_from_args\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[0;32m    119\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the (row, col) shape of the expression.\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m u\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mmul_shapes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
            "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\cvxpy\\utilities\\shape.py:130\u001b[0m, in \u001b[0;36mmul_shapes\u001b[1;34m(lh_shape, rh_shape)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03mGive the shape resulting from multiplying two shapes.\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m    If either of the shapes are scalar.\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m lh_old, rh_old \u001b[38;5;241m=\u001b[39m lh_shape, rh_shape\n\u001b[1;32m--> 130\u001b[0m lh_shape, rh_shape, shape \u001b[38;5;241m=\u001b[39m mul_shapes_promote(lh_shape, rh_shape)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lh_shape \u001b[38;5;241m!=\u001b[39m lh_old:\n\u001b[0;32m    132\u001b[0m     shape \u001b[38;5;241m=\u001b[39m shape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m (shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],)\n",
            "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\cvxpy\\utilities\\shape.py:91\u001b[0m, in \u001b[0;36mmul_shapes_promote\u001b[1;34m(lh_shape, rh_shape)\u001b[0m\n\u001b[0;32m     88\u001b[0m rh_shape \u001b[38;5;241m=\u001b[39m rh_shape \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m,) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(rh_shape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m rh_shape\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lh_shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m rh_shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]:\n\u001b[1;32m---> 91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible dimensions \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (lh_shape, rh_shape))\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Calculate resulting shape for higher-dimensional arrays\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lh_shape) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(rh_shape) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
            "\u001b[1;31mValueError\u001b[0m: Incompatible dimensions (1, 34) (26, 1)"
          ]
        }
      ],
      "source": [
        "# First, let's implement a kernel SVM classifier\n",
        "def kernel_svm(X, Y, kernel_func, gamma=0.1):\n",
        "    \"\"\"\n",
        "    Implement a kernel SVM classifier\n",
        "    \n",
        "    Parameters:\n",
        "    X: Training data points (n_samples, n_features)\n",
        "    Y: Training data points of the other class (m_samples, n_features)\n",
        "    kernel_func: Kernel function to use\n",
        "    gamma: Parameter controlling the trade-off between margin and misclassification\n",
        "    \n",
        "    Returns:\n",
        "    alpha_x: Dual variables for X\n",
        "    alpha_y: Dual variables for Y\n",
        "    b: Offset of the hyperplane\n",
        "    \"\"\"\n",
        "    n, d = X.shape  # n samples, d features for X\n",
        "    m, _ = Y.shape  # m samples for Y\n",
        "    \n",
        "    # Compute the kernel matrices\n",
        "    K_xx = np.zeros((n, n))\n",
        "    K_xy = np.zeros((n, m))\n",
        "    K_yy = np.zeros((m, m))\n",
        "    \n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            K_xx[i, j] = kernel_func(X[i], X[j])\n",
        "    \n",
        "    for i in range(n):\n",
        "        for j in range(m):\n",
        "            K_xy[i, j] = kernel_func(X[i], Y[j])\n",
        "    \n",
        "    for i in range(m):\n",
        "        for j in range(m):\n",
        "            K_yy[i, j] = kernel_func(Y[i], Y[j])\n",
        "    \n",
        "    # Define the optimization variables\n",
        "    alpha_x = cp.Variable(n)  # dual variables for X\n",
        "    alpha_y = cp.Variable(m)  # dual variables for Y\n",
        "    \n",
        "    # Define the objective function (dual problem)\n",
        "    obj = cp.Maximize(\n",
        "        cp.sum(alpha_x) + cp.sum(alpha_y) - \n",
        "        0.5 * cp.quad_form(alpha_x, K_xx) - \n",
        "        0.5 * cp.quad_form(alpha_y, K_yy) - \n",
        "        cp.sum(cp.multiply(K_xy, cp.reshape(alpha_x, (n, 1)) @ cp.reshape(alpha_y, (1, m))))\n",
        "    )\n",
        "    \n",
        "    # Define the constraints\n",
        "    constraints = [\n",
        "        alpha_x >= 0,\n",
        "        alpha_x <= gamma,\n",
        "        alpha_y >= 0,\n",
        "        alpha_y <= gamma,\n",
        "        cp.sum(alpha_x) == cp.sum(alpha_y)\n",
        "    ]\n",
        "    \n",
        "    # Solve the problem\n",
        "    problem = cp.Problem(obj, constraints)\n",
        "    problem.solve()\n",
        "    \n",
        "    # Compute the bias term b\n",
        "    # Find support vectors (points with 0 < alpha < gamma)\n",
        "    sv_x_idx = np.where((alpha_x.value > 1e-5) & (alpha_x.value < gamma - 1e-5))[0]\n",
        "    sv_y_idx = np.where((alpha_y.value > 1e-5) & (alpha_y.value < gamma - 1e-5))[0]\n",
        "    \n",
        "    if len(sv_x_idx) > 0:\n",
        "        b_x = np.mean([1 - sum(alpha_x.value[j] * K_xx[j, i] for j in range(n)) + \n",
        "                      sum(alpha_y.value[j] * K_xy[i, j] for j in range(m)) \n",
        "                      for i in sv_x_idx])\n",
        "    else:\n",
        "        b_x = 0\n",
        "    \n",
        "    if len(sv_y_idx) > 0:\n",
        "        b_y = np.mean([-1 - sum(alpha_y.value[j] * K_yy[j, i] for j in range(m)) + \n",
        "                       sum(alpha_x.value[j] * K_xy[j, i] for j in range(n)) \n",
        "                       for i in sv_y_idx])\n",
        "    else:\n",
        "        b_y = 0\n",
        "    \n",
        "    # Average the two estimates if both are available\n",
        "    if len(sv_x_idx) > 0 and len(sv_y_idx) > 0:\n",
        "        b = (b_x + b_y) / 2\n",
        "    elif len(sv_x_idx) > 0:\n",
        "        b = b_x\n",
        "    elif len(sv_y_idx) > 0:\n",
        "        b = b_y\n",
        "    else:\n",
        "        b = 0\n",
        "    \n",
        "    return alpha_x.value, alpha_y.value, b\n",
        "\n",
        "# Define different kernel functions\n",
        "def linear_kernel(x, y):\n",
        "    return np.dot(x, y)\n",
        "\n",
        "def polynomial_kernel(x, y, degree=2, coef0=1):\n",
        "    return (np.dot(x, y) + coef0) ** degree\n",
        "\n",
        "def rbf_kernel(x, y, sigma=1.0):\n",
        "    return np.exp(-np.sum((x - y) ** 2) / (2 * sigma ** 2))\n",
        "\n",
        "def sigmoid_kernel(x, y, alpha=1.0, c=0):\n",
        "    return np.tanh(alpha * np.dot(x, y) + c)\n",
        "\n",
        "# Function to make predictions with kernel SVM\n",
        "def kernel_svm_predict(X_test, X_train, Y_train, alpha_x, alpha_y, b, kernel_func):\n",
        "    \"\"\"\n",
        "    Make predictions with kernel SVM\n",
        "    \n",
        "    Parameters:\n",
        "    X_test: Test data points\n",
        "    X_train: Training data points of class X\n",
        "    Y_train: Training data points of class Y\n",
        "    alpha_x: Dual variables for X\n",
        "    alpha_y: Dual variables for Y\n",
        "    b: Offset of the hyperplane\n",
        "    kernel_func: Kernel function to use\n",
        "    \n",
        "    Returns:\n",
        "    predictions: Predicted values for X_test\n",
        "    \"\"\"\n",
        "    n_test = len(X_test)\n",
        "    predictions = np.zeros(n_test)\n",
        "    \n",
        "    for i in range(n_test):\n",
        "        f_x = 0\n",
        "        # Contribution from X points\n",
        "        for j in range(len(X_train)):\n",
        "            f_x += alpha_x[j] * kernel_func(X_test[i], X_train[j])\n",
        "        # Contribution from Y points\n",
        "        for j in range(len(Y_train)):\n",
        "            f_x -= alpha_y[j] * kernel_func(X_test[i], Y_train[j])\n",
        "        # Add the bias term\n",
        "        f_x += b\n",
        "        predictions[i] = f_x\n",
        "    \n",
        "    return predictions\n",
        "\n",
        "# Function to evaluate kernel SVM\n",
        "def evaluate_kernel_svm(X_test, Y_test, X_train, Y_train, alpha_x, alpha_y, b, kernel_func):\n",
        "    \"\"\"\n",
        "    Evaluate kernel SVM on test data\n",
        "    \n",
        "    Parameters:\n",
        "    X_test: Test data points of class X\n",
        "    Y_test: Test data points of class Y\n",
        "    X_train: Training data points of class X\n",
        "    Y_train: Training data points of class Y\n",
        "    alpha_x: Dual variables for X\n",
        "    alpha_y: Dual variables for Y\n",
        "    b: Offset of the hyperplane\n",
        "    kernel_func: Kernel function to use\n",
        "    \n",
        "    Returns:\n",
        "    metrics: Dictionary containing various performance metrics\n",
        "    \"\"\"\n",
        "    # Make predictions\n",
        "    X_predictions = kernel_svm_predict(X_test, X_train, Y_train, alpha_x, alpha_y, b, kernel_func)\n",
        "    Y_predictions = kernel_svm_predict(Y_test, X_train, Y_train, alpha_x, alpha_y, b, kernel_func)\n",
        "    \n",
        "    # Count correct predictions\n",
        "    X_correct = np.sum(X_predictions > 0)\n",
        "    Y_correct = np.sum(Y_predictions < 0)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    total_samples = len(X_test) + len(Y_test)\n",
        "    \n",
        "    # True positives: X points correctly classified as X\n",
        "    TP = X_correct\n",
        "    # False positives: Y points incorrectly classified as X\n",
        "    FP = len(Y_test) - Y_correct\n",
        "    # True negatives: Y points correctly classified as Y\n",
        "    TN = Y_correct\n",
        "    # False negatives: X points incorrectly classified as Y\n",
        "    FN = len(X_test) - X_correct\n",
        "    \n",
        "    # Accuracy: Overall proportion of correct predictions\n",
        "    accuracy = (TP + TN) / total_samples\n",
        "    \n",
        "    # Precision: Proportion of true positives among all positive predictions\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "    \n",
        "    # Recall (Sensitivity): Proportion of true positives among all actual positives\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "    \n",
        "    # Specificity: Proportion of true negatives among all actual negatives\n",
        "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
        "    \n",
        "    # F1 Score: Harmonic mean of precision and recall\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    \n",
        "    # Balanced Accuracy: Average of recall and specificity\n",
        "    balanced_accuracy = (recall + specificity) / 2\n",
        "    \n",
        "    # Misclassification Rate: Proportion of incorrect predictions\n",
        "    misclassification_rate = 1 - accuracy\n",
        "    \n",
        "    # Geometric Mean: Square root of the product of recall and specificity\n",
        "    g_mean = np.sqrt(recall * specificity)\n",
        "    \n",
        "    # Store all metrics in a dictionary\n",
        "    metrics = {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'specificity': specificity,\n",
        "        'f1_score': f1_score,\n",
        "        'balanced_accuracy': balanced_accuracy,\n",
        "        'misclassification_rate': misclassification_rate,\n",
        "        'g_mean': g_mean,\n",
        "        'TP': TP,\n",
        "        'FP': FP,\n",
        "        'TN': TN,\n",
        "        'FN': FN\n",
        "    }\n",
        "    \n",
        "    return metrics\n",
        "\n",
        "# Function to plot kernel SVM decision boundary\n",
        "def plot_kernel_svm(X, Y, X_train, Y_train, alpha_x, alpha_y, b, kernel_func, title=\"Kernel SVM Classifier\"):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    \n",
        "    # Plot the data points\n",
        "    plt.scatter(X[:, 0], X[:, 1], c='blue', label='Class X')\n",
        "    plt.scatter(Y[:, 0], Y[:, 1], c='red', label='Class Y')\n",
        "    \n",
        "    # Plot the decision boundary\n",
        "    x_min, x_max = min(np.min(X[:, 0]), np.min(Y[:, 0])) - 0.5, max(np.max(X[:, 0]), np.max(Y[:, 0])) + 0.5\n",
        "    y_min, y_max = min(np.min(X[:, 1]), np.min(Y[:, 1])) - 0.5, max(np.max(X[:, 1]), np.max(Y[:, 1])) + 0.5\n",
        "    \n",
        "    # Create a grid of points\n",
        "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
        "                         np.linspace(y_min, y_max, 100))\n",
        "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
        "    \n",
        "    # Compute the decision function values\n",
        "    Z = kernel_svm_predict(grid, X_train, Y_train, alpha_x, alpha_y, b, kernel_func)\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    \n",
        "    # Plot the decision boundary and margins\n",
        "    plt.contour(xx, yy, Z, levels=[-1, 0, 1], colors=['r', 'k', 'b'], linestyles=['--', '-', '--'])\n",
        "    \n",
        "    # Fill the regions\n",
        "    plt.contourf(xx, yy, Z, levels=[-100, -1, 1, 100], colors=['#FFAAAA', '#FFFFFF', '#AAAAFF'], alpha=0.3)\n",
        "    \n",
        "    plt.title(title)\n",
        "    plt.xlabel('Feature 1')\n",
        "    plt.ylabel('Feature 2')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Test different kernel functions\n",
        "kernels = {\n",
        "    'Linear': linear_kernel,\n",
        "    'Polynomial (degree=2)': lambda x, y: polynomial_kernel(x, y, degree=2),\n",
        "    'Polynomial (degree=3)': lambda x, y: polynomial_kernel(x, y, degree=3),\n",
        "    'RBF (sigma=0.5)': lambda x, y: rbf_kernel(x, y, sigma=0.5),\n",
        "    'RBF (sigma=1.0)': lambda x, y: rbf_kernel(x, y, sigma=1.0),\n",
        "    'RBF (sigma=2.0)': lambda x, y: rbf_kernel(x, y, sigma=2.0),\n",
        "    'Sigmoid (alpha=0.5)': lambda x, y: sigmoid_kernel(x, y, alpha=0.5),\n",
        "    'Sigmoid (alpha=1.0)': lambda x, y: sigmoid_kernel(x, y, alpha=1.0)\n",
        "}\n",
        "\n",
        "# Store results for each kernel\n",
        "kernel_results = {}\n",
        "\n",
        "# Test each kernel\n",
        "for kernel_name, kernel_func in kernels.items():\n",
        "    print(f\"\\nTraining kernel SVM with {kernel_name} kernel...\")\n",
        "    \n",
        "    # Train the kernel SVM\n",
        "    alpha_x, alpha_y, b = kernel_svm(X_train_2, Y_train_2, kernel_func)\n",
        "    \n",
        "    # Evaluate on test data\n",
        "    metrics = evaluate_kernel_svm(X_test_2, Y_test_2, X_train_2, Y_train_2, alpha_x, alpha_y, b, kernel_func)\n",
        "    \n",
        "    # Store the results\n",
        "    kernel_results[kernel_name] = {\n",
        "        'alpha_x': alpha_x,\n",
        "        'alpha_y': alpha_y,\n",
        "        'b': b,\n",
        "        'metrics': metrics\n",
        "    }\n",
        "    \n",
        "    # Print the metrics\n",
        "    print(f\"Performance Metrics for {kernel_name} Kernel SVM on Dataset 2 Test Set:\")\n",
        "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
        "    print(f\"F1 Score: {metrics['f1_score']:.4f}\")\n",
        "    print(f\"Balanced Accuracy: {metrics['balanced_accuracy']:.4f}\")\n",
        "    print(f\"G-Mean: {metrics['g_mean']:.4f}\")\n",
        "    \n",
        "    # Plot the classifier\n",
        "    plot_kernel_svm(X_train_2, Y_train_2, X_train_2, Y_train_2, alpha_x, alpha_y, b, kernel_func, \n",
        "                   title=f\"{kernel_name} Kernel SVM for Dataset 2 - Training Data\")\n",
        "    plot_kernel_svm(X_test_2, Y_test_2, X_train_2, Y_train_2, alpha_x, alpha_y, b, kernel_func, \n",
        "                   title=f\"{kernel_name} Kernel SVM for Dataset 2 - Test Data\")\n",
        "\n",
        "# Find the best kernel based on F1 score\n",
        "best_kernel = max(kernel_results.items(), key=lambda x: x[1]['metrics']['f1_score'])\n",
        "best_kernel_name = best_kernel[0]\n",
        "best_metrics = best_kernel[1]['metrics']\n",
        "\n",
        "print(f\"\\nBest Kernel: {best_kernel_name}\")\n",
        "print(f\"Best F1 Score: {best_metrics['f1_score']:.4f}\")\n",
        "print(f\"Corresponding Accuracy: {best_metrics['accuracy']:.4f}\")\n",
        "print(f\"Corresponding Balanced Accuracy: {best_metrics['balanced_accuracy']:.4f}\")\n",
        "print(f\"Corresponding G-Mean: {best_metrics['g_mean']:.4f}\")\n",
        "\n",
        "# Compare with linear SVM\n",
        "print(\"\\nComparison with Linear SVM:\")\n",
        "print(f\"Linear SVM - Accuracy: {metrics_2['accuracy']:.4f}\")\n",
        "print(f\"Best Kernel SVM - Accuracy: {best_metrics['accuracy']:.4f}\")\n",
        "print(f\"Linear SVM - F1 Score: {metrics_2['f1_score']:.4f}\")\n",
        "print(f\"Best Kernel SVM - F1 Score: {best_metrics['f1_score']:.4f}\")\n",
        "print(f\"Linear SVM - Balanced Accuracy: {metrics_2['balanced_accuracy']:.4f}\")\n",
        "print(f\"Best Kernel SVM - Balanced Accuracy: {best_metrics['balanced_accuracy']:.4f}\")\n",
        "print(f\"Linear SVM - G-Mean: {metrics_2['g_mean']:.4f}\")\n",
        "print(f\"Best Kernel SVM - G-Mean: {best_metrics['g_mean']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6Qa5_jZzw6L"
      },
      "source": [
        "# Answers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_8R5cKxz0TF"
      },
      "source": [
        "*   Name: Jiaqiang Jing\n",
        "*   Surname: Jing\n",
        "*   CID: 06007965"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-TFEaOxz7XU"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "gkGSTu0CyV0U",
        "Tr1_keJoyZDp",
        "y8-nQi54xtXD",
        "CgaT8uzm_ZqC"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
